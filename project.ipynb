{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La première partie du projet sera liée à l'étude des data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total de NaN : 0\n",
      "Colonnes catégoriques trouvées : ['sample_name', 'device_serial', 'substance_form_display', 'measure_type_display', 'prod_substance']\n",
      "Les colonnes catégoriques ont été transformées en dummies.\n",
      "          sample_name device_serial  substance_form_display  \\\n",
      "0            11140009    M1-1000112      Homogenized Powder   \n",
      "1     22.0401-P002.02    M1-1000109  Non homogenized powder   \n",
      "2     22.0117-P001.02    M1-1000100  Non homogenized powder   \n",
      "3        20.0163-P009      N1-00196             Unspecified   \n",
      "4        19.0286-P005      N1-00196             Unspecified   \n",
      "...               ...           ...                     ...   \n",
      "1295  22.0267-P001.01    M1-1000100      Homogenized Powder   \n",
      "1296         11060000    M1-1000144      Homogenized Powder   \n",
      "1297     22.0368-P002    M1-1000130      Homogenized Powder   \n",
      "1298  22.0342-P002.04    M1-1000109      Homogenized Powder   \n",
      "1299  22.0401-P001.04    M1-1000109      Homogenized Powder   \n",
      "\n",
      "     measure_type_display prod_substance     PURITY     908.1     914.3  \\\n",
      "0          Direct contact         Heroin  58.500000  0.044734  0.042720   \n",
      "1          Direct contact         Heroin  18.600000  0.063695  0.056980   \n",
      "2          Direct contact         Heroin  19.881719  0.050358  0.044910   \n",
      "3          Direct contact         Heroin  52.500000  0.525050  0.520434   \n",
      "4          Direct contact         Heroin  48.900000  0.479365  0.467401   \n",
      "...                   ...            ...        ...       ...       ...   \n",
      "1295       Direct contact         Heroin  10.100000  0.107930  0.103983   \n",
      "1296       Direct contact         Heroin  44.900000  0.040564  0.041559   \n",
      "1297       Direct contact         Heroin  53.400000  0.106459  0.108084   \n",
      "1298       Direct contact         Heroin  13.600000  0.075628  0.068853   \n",
      "1299       Direct contact         Heroin  19.600000  0.058483  0.051543   \n",
      "\n",
      "         920.5     926.7  ...    1620.5    1626.6    1632.8      1639  \\\n",
      "0     0.041361  0.040055  ...  0.003972  0.007906  0.012490  0.018123   \n",
      "1     0.050080  0.043339  ...  0.093002  0.099668  0.108805  0.117120   \n",
      "2     0.039148  0.033730  ...  0.083369  0.090485  0.100462  0.109033   \n",
      "3     0.517187  0.516377  ...  0.357223  0.370060  0.386062  0.404460   \n",
      "4     0.456680  0.446148  ...  0.350973  0.366094  0.384536  0.405034   \n",
      "...        ...       ...  ...       ...       ...       ...       ...   \n",
      "1295  0.100068  0.096422  ...  0.133917  0.138535  0.145144  0.151008   \n",
      "1296  0.042435  0.043870  ... -0.007995 -0.004902 -0.001237  0.003390   \n",
      "1297  0.109983  0.109541  ...  0.052178  0.056051  0.060666  0.066257   \n",
      "1298  0.062538  0.056079  ...  0.094620  0.101527  0.111090  0.119861   \n",
      "1299  0.044479  0.037586  ...  0.082725  0.089156  0.097976  0.106049   \n",
      "\n",
      "        1645.2    1651.4    1657.6    1663.8      1670    1676.2  \n",
      "0     0.025070  0.033235  0.042502  0.052237  0.061383  0.068823  \n",
      "1     0.121947  0.125137  0.128688  0.133501  0.138187  0.140248  \n",
      "2     0.113411  0.117053  0.121665  0.128366  0.134636  0.136961  \n",
      "3     0.425567  0.450527  0.479066  0.508943  0.539349  0.564486  \n",
      "4     0.426582  0.450564  0.477045  0.504142  0.531764  0.553650  \n",
      "...        ...       ...       ...       ...       ...       ...  \n",
      "1295  0.153738  0.155602  0.158525  0.163138  0.167623  0.169048  \n",
      "1296  0.009303  0.016472  0.023843  0.031736  0.039568  0.046056  \n",
      "1297  0.073435  0.083057  0.094621  0.106288  0.117307  0.126626  \n",
      "1298  0.124868  0.128340  0.132605  0.138737  0.144825  0.148246  \n",
      "1299  0.110971  0.114777  0.119445  0.125784  0.132106  0.135891  \n",
      "\n",
      "[1300 rows x 131 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd \n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.stats import zscore\n",
    "\n",
    "\n",
    "file_path = \"/Users/alicepriolet/Desktop/ML/epfl-bio-322-2024/train.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "isNan = True # permet de choisir si la methode des Nan doit etre utilisee \n",
    "nb_max_Nan = 10\n",
    "      \n",
    "\n",
    "    \n",
    "def process_Nan(data):\n",
    "    # Compter le nombre total de NaN dans le fichier\n",
    "    nombre_nan = data.isna().sum().sum()  \n",
    "    print(f\"Nombre total de NaN : {nombre_nan}\")\n",
    "    \n",
    "    if nombre_nan >= nb_max_Nan:\n",
    "        # Remplir les NaN avec la moyenne des colonnes si nombre_nan > nb_max_Nan \n",
    "        data.fillna(data.mean(), inplace=True)\n",
    "    else:\n",
    "        # Supprimer les lignes contenant des NaN si nombre_nan < nb_max_Nan\n",
    "        data = data.dropna()  # Supprime les lignes avec au moins un NaN\n",
    "        \n",
    "        \n",
    " \n",
    "def preprocess_categorical(data):\n",
    "    \"\"\"\n",
    "    Préprocesser les colonnes catégoriques d'un DataFrame en utilisant pd.get_dummies.\n",
    "    \n",
    "    Args:\n",
    "    - data (pd.DataFrame): Tableau de données à prétraiter.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame avec colonnes catégoriques transformées en dummies.\n",
    "    \"\"\"\n",
    "    # Identifier les colonnes de type 'object' (catégoriques)\n",
    "    string_columns = data.select_dtypes(include=['object']).columns\n",
    "    \n",
    "    if not string_columns.empty:\n",
    "        print(f\"Colonnes catégoriques trouvées : {list(string_columns)}\")\n",
    "        # Appliquer pd.get_dummies pour transformer les colonnes catégoriques\n",
    "        data = pd.get_dummies(data, columns=string_columns, drop_first=True)\n",
    "        print(\"Les colonnes catégoriques ont été transformées en dummies.\")\n",
    "    else:\n",
    "        print(\"Aucune colonne catégorique trouvée.\")\n",
    "    \n",
    "    return data\n",
    " \n",
    " \n",
    "if isNan == True: \n",
    "    process_Nan(data)\n",
    "else :\n",
    "    print('No Nan processing has been performed')\n",
    "    \n",
    "preprocess_categorical(data)       \n",
    "print(data)\n",
    "spectrum = data.iloc[:, 6:] # permet de standardiser les valeurs d infrarouge \n",
    "spectrum_filtered = pd.DataFrame(savgol_filter(spectrum, 7, 3, deriv = 2, axis = 0))\n",
    "spectrum_filtered_standardized = zscore(spectrum_filtered, axis = 1)\n",
    "\n",
    "#plt.plot(spectrum_filtered[0],spectrum_filtered[6])\n",
    "#plt.show()\n",
    "#print(spectrum_filtered_standardized)  # Statistiques descriptives\n",
    "\n",
    "\"\"\"Preprocessing functions.\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def variance_filter(data, threshold):\n",
    "    \"\"\"\n",
    "    Applique un filtre de variance sur un fichier CSV en supprimant les colonnes avec faible variance.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Chemin du fichier CSV.\n",
    "        threshold (float): Seuil de variance en dessous duquel les colonnes seront supprimées.\n",
    "        output_file (str): Nom du fichier CSV où sauvegarder les données filtrées (par défaut : \"filtered_data.csv\").\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculer la variance pour chaque colonne numérique\n",
    "    variances = data.std(axis=0)  # Écart type (équivalent à la racine carrée de la variance)\n",
    "    \n",
    "    # Identifier les colonnes à supprimer\n",
    "    del_cols = variances[variances <= threshold].index  # Noms des colonnes avec faible variance\n",
    "    \n",
    "    # Supprimer les colonnes identifiées\n",
    "    filtered_data = data.drop(columns=del_cols)\n",
    "    \n",
    "    # Sauvegarder les données filtrées dans un nouveau fichier CSV\n",
    "    #filtered_data.to_csv(filtered_data.csv, index=False)\n",
    "    \n",
    "    # Afficher les résultats\n",
    "    print(f\"Colonnes supprimées (variance <= {threshold}): {list(del_cols)}\")\n",
    "    print(f\"Les données filtrées ont été sauvegardées dans '{output_file}'.\")\n",
    "\n",
    "\n",
    "def standardization(\n",
    "    data: np.array, mean: np.array = None, std: np.array = None\n",
    ") -> tuple[np.array, np.array, np.array]:\n",
    "    \"\"\"\n",
    "    Standardize the data. If mean or std is None, we compute them.\n",
    "\n",
    "    Args:\n",
    "        data (np.array): data matrix (N,D)\n",
    "        mean (np.array, optional): means for standardization. Defaults to None.\n",
    "        std (np.array, optional): standard deviations for standardization. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        tuple[np.array, float, float]: standardized data matrix, columns means and standard deviations\n",
    "    \"\"\"\n",
    "    if (mean is None) or (std is None):\n",
    "        mean = np.mean(data, axis=0)\n",
    "        std = np.std(data, axis=0)\n",
    "\n",
    "    return (data - mean) / std, mean, std\n",
    "\n",
    "\n",
    "def add_bias_term(x: np.array) -> np.array:\n",
    "    \"\"\"\n",
    "    Add a column of ones on the left of the data matrix\n",
    "\n",
    "    Args:\n",
    "        x (np.array): data matrix (N,D)\n",
    "\n",
    "    Returns:\n",
    "        np.array: data matrix with bias terms\n",
    "    \"\"\"\n",
    "    num_samples = x.shape[0]\n",
    "    tx = np.c_[np.ones(num_samples), x]\n",
    "\n",
    "    return tx\n",
    "\n",
    "\n",
    "def preprocess_data(\n",
    "    x_tr: np.array, x_te: np.array, nan_threshold: float = 0, var_threshold: float = 0\n",
    ") -> tuple[np.array, np.array]:\n",
    "    \"\"\"\n",
    "    Call preprocessing functions\n",
    "\n",
    "        x_tr (np.array): raw x_train (N,)\n",
    "        x_te (np.array): row x_test (N_test,)\n",
    "        nan_threshold (float, optional): threshold for Nan values. Defaults to 0.\n",
    "        var_threshold (float, optional): threshold for variance. Defaults to 0.\n",
    "\n",
    "    Returns:\n",
    "        tuple[np.array, np.array]: x_train and x_test after preprocessing\n",
    "    \"\"\"\n",
    "    # Remove non relevant features :\n",
    "    x_tr, del_features = nan_filter(x_tr, threshold=nan_threshold)\n",
    "    x_te = np.delete(x_te, del_features, axis=1)\n",
    "\n",
    "    # Replace NaN values and remove zero variance features in training set :\n",
    "    x_tr = fill_nan_mean(x_tr)\n",
    "    x_tr, del_features = variance_filter(x_tr, threshold=var_threshold)\n",
    "\n",
    "    # Remove same features and replace NaN values in testing set :\n",
    "    x_te = np.delete(x_te, del_features, axis=1)\n",
    "    x_te = fill_nan_mean(x_te)\n",
    "\n",
    "    # Standardize data :\n",
    "    x_tr, mean_tr, std_tr = standardization(x_tr)\n",
    "    x_te, _, _ = standardization(x_te, mean_tr, std_tr)\n",
    "\n",
    "    # Add Bias term :\n",
    "    tx_tr = add_bias_term(x_tr)\n",
    "    tx_te = add_bias_term(x_te)\n",
    "\n",
    "    return tx_tr, tx_te\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLCourse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
