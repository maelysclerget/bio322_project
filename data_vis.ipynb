


def data_visualisation():
    
    # Créer un dossier pour sauvegarder les graphiques
    output_dir = 'data_visualisation'
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
        print(f"Répertoire créé : {output_dir}")
        
    data_train = pd.read_csv('/Users/alicepriolet/Desktop/ML/epfl-bio-322-2024/train.csv')
    data_test = pd.read_csv('/Users/alicepriolet/Desktop/ML/epfl-bio-322-2024/test.csv')
    print("The size of the train data set is",data_train.shape)
    #print(data_test.shape)
    
    categorical_columns = data_train.select_dtypes(include=['object', 'category']).columns
    print("There is ",len(categorical_columns),"categorial columns")
    
        # Répartition des colonnes catégoriques et sauvegarde des graphiques
    for col in categorical_columns:
        plt.figure(figsize=(15, 15))
        sns.countplot(x=col, data=data_train, palette='viridis')
        plt.title(f"Repartition of the categories in {col}")
        plt.xlabel(col)
        plt.ylabel("Frequency")
        plt.xticks(rotation=45)
        
        # Sauvegarder le graphique
        graph_path = os.path.join(output_dir, f"category_distribution_{col}.png")
        plt.savefig(graph_path)
        plt.close()
        #print(f"Graphic saved : {graph_path}")
    
    # Identify the samples that appear several times in the data set
    duplicate_samples = data_train[data_train.duplicated(subset='sample_name', keep=False)]

    # Afficher les indices et les noms des échantillons dupliqués
    #for index, row in duplicate_samples.iterrows():
    #    print(f"Index: {index}, Sample Name: {row['sample_name']}")

    # Print the total number of duplicated samples
    print(f"Nombre total de noms de samples dupliqués : {duplicate_samples['sample_name'].nunique()}")
    print("Nombre total de samples concernés", len(duplicate_samples))
    
    
    
    # Count the number of columns of infrared spectrum measurements
    spectr_columns = [col for col in data_test.columns if col.startswith('9') or col.startswith('1')]
    spectr_count = len(spectr_columns)
    
    print(f"Number of Infrared Spectrum columns is : {spectr_count}")
    
    # Allows us to see the purity curve 
    plt.figure(figsize=(10, 6))
    sns.histplot(data_train['PURITY'], kde=True, bins=30, color='blue')
    plt.title("Distribution de la variable PURITY")
    plt.xlabel("PURITY")
    plt.ylabel("Fréquence")
    
    graph_path = os.path.join(output_dir, f"purity_frequence.png")
    plt.savefig(graph_path)
    plt.close()
    #print(f"Graphique sauvegardé : {graph_path}")

    plt.figure(figsize=(10, 6))
    sns.scatterplot(x=data_train['908.1'], y=data_train['PURITY'], alpha=0.7)
    sns.scatterplot(x=data_train['914.3'], y=data_train['PURITY'], alpha=0.7)
    sns.scatterplot(x=data_train['920.5'], y=data_train['PURITY'], alpha=0.7)
    sns.scatterplot(x=data_train['1316.9'], y=data_train['PURITY'], alpha=0.7)
    sns.scatterplot(x=data_train['1676.2'], y=data_train['PURITY'], alpha=0.7)
    plt.title("Relation between 908.1, 914.3, 920.5. 1316.9 et 1676.2 and Purity")
    plt.xlabel("908.1, 914.3, 920.5. 1316.9 and 1676.2")
    plt.ylabel("Purity")
    
    graph_path = os.path.join(output_dir, f"relation_between_purity_and_spectrum.png")
    plt.savefig(graph_path)
    plt.close()
    print(f"Graphique sauvegardé : {graph_path}")
    

    data_train['908.1_residuals'] = data_train['908.1'] - data_train['908.1'].median()
    plt.figure(figsize=(10, 6))
    sns.histplot(data_train['908.1_residuals'], kde=True, bins=30, color='purple')
    plt.title("Distribution des résidus de 908.1")
    plt.xlabel("Résidus de 908.1")
    plt.ylabel("Fréquence")
    
    graph_path = os.path.join(output_dir, f"spectrum_distribution.png")
    plt.savefig(graph_path)
    plt.close()
    print(f"Graphique sauvegardé : {graph_path}")

    data_reduced = data_train.iloc[:, 6:]
    corr_matrix = data_reduced.corr()  # Matrice de corrélation
    plt.figure(figsize=(12, 8))
    sns.heatmap(corr_matrix, cmap='coolwarm', annot=False, cbar=True)
    plt.title("Matrice de corrélation des variables numériques")
    
    graph_path = os.path.join(output_dir, f"correlation_matrix.png")
    plt.savefig(graph_path)
    plt.close()
    print(f"Graphique sauvegardé : {graph_path}")

    top_5_correlations = (
    corr_matrix
    .abs()  # Prendre les valeurs absolues des corrélations
    .unstack()  # Convertir en série pour itérer
    .sort_values(ascending=False)  # Trier par corrélation décroissante
    .drop_duplicates()  # Supprimer les doublons
    )

    # Filtrer pour exclure les corrélations de la diagonale (valeur de corrélation = 1)
    top_5_corr = top_5_correlations[top_5_correlations < 1].head(5)

    print("voici les 5 les plus corrélés",top_5_correlations)
    
    mean_purity = data_train['PURITY'].mean()
    std_purity= data_train['PURITY'].std()
    
    print('purity mean is',mean_purity)
    print('purity std is',std_purity)
    
    # Create histogram
    sns.kdeplot(data = data_train, x = 'PURITY', fill = True)
    plt.title('Purity distribution')
    plt.xlabel('Purity')
    plt.ylabel('Frequency')
    
    graph_path = os.path.join(output_dir, f"frequency_purity.png")
    plt.savefig(graph_path)
    plt.close()
    print(f"Graphique sauvegardé : {graph_path}")
    
    # Filtrer et afficher les noms des échantillons ayant une pureté < 10
    low_purity_samples = data_train[data_train['PURITY'] < 10]['sample_name']

    # Afficher les noms des échantillons
    #for index, sample in low_purity_samples.items():
        #print(f"Index: {index}, Sample Name: {sample}")
        
    print(f"Nombre total de samples avec une pureté < 10 : {len(low_purity_samples)}")
    
    # Filtrer et afficher les noms des échantillons ayant une pureté > 60
    high_purity_samples = data_train[data_train['PURITY'] > 60]['sample_name']

    # Afficher les noms des échantillons
    for index, sample in high_purity_samples.items():
        print(f"Index: {index}, Sample Name: {sample}")
        
    print(f"Nombre total de samples avec une pureté > 60 : {len(high_purity_samples)}")
    
